{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64529963",
   "metadata": {},
   "source": [
    "# Adversity Outcome Prediction Training Pipeline\n",
    "## Aim\n",
    "To implement an adversity outcome prediction training pipeline to benchmark the metrics of logistic regression models applied to the authentic and synthetic MIMIC-III data processed through the FIDDLE pipeline outlined in Tang et al. 2020. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfac647d",
   "metadata": {},
   "source": [
    "# Differences between FIDDLE and Yoon et al. 2023 features for mortality prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b3369e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets\n",
    "import os\n",
    "import sparse\n",
    "import json\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import itertools\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import sqlalchemy as db\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "from dask import dataframe as dd\n",
    "from IPython.display import display, HTML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e183921",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_features = '../databases/experiment_data/features/mortality_48h'\n",
    "\n",
    "# Generate relevant static features\n",
    "s = sparse.load_npz(f'{directory_features}/s.npz')\n",
    "\n",
    "# Generate relevant temporal features\n",
    "X = sparse.load_npz(f'{directory_features}/X.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7351d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display feature datasets\n",
    "\n",
    "\n",
    "##### Load FIDDLE's mortality_48h task features into pandas\n",
    "# Load static variables into a pandas table\n",
    "s_names = json.load(open(f'{directory_features}/s.feature_names.json', 'r'))\n",
    "df_S = pd.DataFrame(s.todense(), columns=s_names)\n",
    "\n",
    "# Load temporal data into pandas table\n",
    "X_names = json.load(open(f'{directory_features}/X.feature_names.json', 'r'))\n",
    "df_X = pd.DataFrame(X.todense().reshape(-1, X.shape[-1]), columns=X_names)\n",
    "\n",
    "display(df_S)\n",
    "display(df_X)\n",
    "list(df_S.columns.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbcc0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert D_ITEMS into a usable dictionary to identify features and tables\n",
    "\n",
    "D_items = open('../databases/mimic-iii-clinical-database-1.4-original/D_ITEMS.csv', 'r')\n",
    "D_labitems = open('../databases/mimic-iii-clinical-database-1.4-original/D_LABITEMS.csv', 'r')\n",
    "ID_dict = {}\n",
    "\n",
    "name_code = {}\n",
    "\n",
    "for line in D_items.readlines()[1:]:\n",
    "    split = line.split(',')\n",
    "    code = split[1]\n",
    "    name = split[2].replace('\"', '')\n",
    "    table = split[5].replace('\"', '') ### CHANGED\n",
    "    \n",
    "    ID_dict[code] = name\n",
    "    name_code[name] = code\n",
    "\n",
    "for line in D_labitems.readlines()[1:]:\n",
    "    split = line.split(',')\n",
    "    code = split[1]\n",
    "    name = split[2].replace('\"', '')\n",
    "    table = split[5].replace('\"', '') ### CHANGED\n",
    "    \n",
    "    ID_dict[code] = name\n",
    "    name_code[name] = code\n",
    "\n",
    "\n",
    "D_items.close()\n",
    "D_labitems.close()\n",
    "\n",
    "# print(ID_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1dea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FIDDLE_features(feature_names: list) -> set:\n",
    "    '''\n",
    "    Extracts the feature names from the FIDDLE data.\n",
    "    Args:\n",
    "        feature_names: a list of column names from FIDDLE\n",
    "    Returns:\n",
    "        filtered_names: a set of feature names without other ID's and ranges from ordinal encoding\n",
    "    '''\n",
    "    filtered_names = []\n",
    "    \n",
    "    for i in feature_names:\n",
    "        ind = i.find('_')\n",
    "        code_name = i[:ind]\n",
    "        \n",
    "        # If format is 220048: ...\n",
    "        if ' ' in code_name:\n",
    "            continue\n",
    "        \n",
    "        # Convert to name using D_ITEMS if it's a code\n",
    "        elif code_name.isnumeric():\n",
    "            try:\n",
    "                feature = ID_dict[code_name]\n",
    "            \n",
    "            # Code not found in D_ITEMS - TO FIX\n",
    "            except:\n",
    "                feature = code_name\n",
    "        \n",
    "        # Must be name like SysBP otherwise\n",
    "        else:\n",
    "            feature = code_name\n",
    "        \n",
    "        filtered_names.append(feature)\n",
    "    \n",
    "    unique_features = set(filtered_names)\n",
    "    \n",
    "    return unique_features\n",
    "\n",
    "\n",
    "def mimic_features(path: str) -> list:\n",
    "    '''\n",
    "    Extracts the feature names retrieved from Yang et al. 2023 paper and returns a tuple that divides it based on\n",
    "    temporal or static status.\n",
    "    Args:\n",
    "        path: path to the file of features\n",
    "    Returns:\n",
    "        features: a list containing two lists for temporal and static features\n",
    "    '''\n",
    "    features = [[], []]\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for feature in range(len(lines)):\n",
    "            # Before line 76 and line 76 is temporal\n",
    "            if feature < 83:\n",
    "                features[0].append(lines[feature][:-1])\n",
    "            \n",
    "            # After line 76 is static\n",
    "            else:\n",
    "                if lines[feature][-1] == '\\n':\n",
    "                    features[1].append(lines[feature][:-1])\n",
    "                else:\n",
    "                    features[1].append(lines[feature])\n",
    "    features[1] = features[1][:-1]\n",
    "    features[0].append('Measurement Time')\n",
    "\n",
    "    return features\n",
    "\n",
    "def similar_features(list1: set, list2: set) -> tuple:\n",
    "    '''\n",
    "    Discovers the elements that are shared in both list1 and list2.\n",
    "    Args:\n",
    "        list1: a list of elements\n",
    "        list2: a list of elements\n",
    "    Returns:\n",
    "        num, shared: a tuple containing number of shared elements, and a list of the shared elements\n",
    "    '''\n",
    "    shared = []\n",
    "    \n",
    "    # Strip caps and whitespaces for less chance of missing shared features\n",
    "    mod_list2 = []\n",
    "    for i in list2:\n",
    "        mod_list2.append(i.strip().lower())\n",
    "    \n",
    "    # Find shared elements\n",
    "    for i in list1:\n",
    "        if i.strip().lower() in mod_list2:\n",
    "            shared.append(i)\n",
    "    \n",
    "    num = len(shared)\n",
    "    return num, shared\n",
    "\n",
    "\n",
    "##### Obtain unique feature values used in FIDDLE package\n",
    "\n",
    "# Temporal features\n",
    "print('TEMPORAL FEATURES FROM MORTALITY_48H FIDDLE EXPERIMENT')\n",
    "print('-----------------------------------------------------------------------------------------------------------')\n",
    "X_features = FIDDLE_features(X_names)\n",
    "print(f'Number of temporal features: {len(X_features)}\\n')\n",
    "print(f'Features used: {X_features}\\n')\n",
    "\n",
    "# Static features\n",
    "print('STATIC FEATURES FROM MORTALITY_48H FIDDLE EXPERIMENT')\n",
    "print('-----------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "# REMOVED S_FEATURES FOR PRIVACY PURPOSES\n",
    "print(f'Number of static features: {len(s_features)}\\n')\n",
    "print(f'Features used: {s_features}\\n')\n",
    "\n",
    "\n",
    "##### Obtain unique feature values used in Yoon et al. 2023 paper\n",
    "\n",
    "path_features = '../databases/mimic-features.txt'\n",
    "temp_features, static_features = mimic_features(path_features)\n",
    "\n",
    "# Temporal features\n",
    "print('\\nTEMPORAL FEATURES FROM YANG ET AL. 2023 EXPERIMENT')\n",
    "print('-----------------------------------------------------------------------------------------------------------')\n",
    "print(f'Number of temporal features: {len(temp_features)}\\n')\n",
    "print(f'Features used: {temp_features}\\n')\n",
    "\n",
    "# Static features\n",
    "print('STATIC FEATURES FROM YANG ET AL. 2023 EXPERIMENT')\n",
    "print('-----------------------------------------------------------------------------------------------------------')\n",
    "print(f'Number of static features: {len(static_features)}\\n')\n",
    "print(f'Features used: {static_features}\\n')\n",
    "\n",
    "\n",
    "##### Compare features present in both\n",
    "\n",
    "# Temporal features\n",
    "print('\\nSHARED TEMPORAL FEATURES')\n",
    "print('-----------------------------------------------------------------------------------------------------------')\n",
    "numX, shared_X_features = similar_features(temp_features, X_features)\n",
    "print(f'Number of shared temporal features: {numX}\\n')\n",
    "print(f'Temporal features shared:{shared_X_features}')\n",
    "\n",
    "\n",
    "# Static features\n",
    "print('\\nSHARED STATUIC FEATURES')\n",
    "print('-----------------------------------------------------------------------------------------------------------')\n",
    "nums, shared_s_features = similar_features(static_features, s_features)\n",
    "# REMOVED .APPEND METHOD FOR PRIVACY PURPOSES\n",
    "nums += 1\n",
    "print(f'Number of shared temporal features: {nums}\\n')\n",
    "print(f'Temporal features shared:{shared_s_features}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a4bd21",
   "metadata": {},
   "source": [
    "## Importing data\n",
    "### Assumptions\n",
    "The following ID's and features have been assigned together due to their absences on the D_ITEMS.csv:\n",
    "\n",
    "[REMOVED FOR PRIVACY PURPOSES]\n",
    "\n",
    "Factors that were considered in choosing these alternatives include whether the label had an abbreviation the database source. Metavision was prioritised over Carevue in the decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d4fd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = []\n",
    "c = 0\n",
    "replacements = ['220050', '220051', '226512', '220045']\n",
    "\n",
    "for i in X_features:\n",
    "    try:\n",
    "        codes.append(name_code[i])\n",
    "    except:\n",
    "        codes.append(replacements[c])\n",
    "        c += 1\n",
    "\n",
    "# changing each to int, so when it's sorted it goes in increasing order\n",
    "for i in range(len(codes)):\n",
    "    codes[i] = int(codes[i])\n",
    "    \n",
    "sorted_codes = sorted(codes)\n",
    "\n",
    "# changing back to str so it can be used as a key value for code_name record\n",
    "for i in range(len(sorted_codes)):\n",
    "    sorted_codes[i] = str(sorted_codes[i])\n",
    "\n",
    "# print sorted codes to each schema\n",
    "fnl_str = ''\n",
    "for i in sorted_codes:\n",
    "    fnl_str += f\"('{i}', pa.float32()),\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4ea468",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "## Outcome definition of mortality\n",
    "In-hospital mortality refers to a patient's death occurring within 28 days of admission, according to various studies (Churpek et al., 2021; Docherty et al., 2021; Group, 2021; UKHSA, 2022). './population/mortality_48h.csv' contains the 'mortality_LABEL' boolean field that represents whether the patient died at time T, where T >= 48 hours, in this case.\n",
    "\n",
    "By observation, and concerning MIMIC-III's ADMISSIONS table, calculating the difference between ADMITTIME and DEATHTIME determines mortality. If the difference in time is less than T=48, then the corresponding example is excluded from the preprocessed data (Tang et al., 2020, p.22). If the patient has died, DISCHTIME should hold the same value as DEATHTIME.\n",
    "\n",
    "The features will be aligned with the key hadm_id 'hospital admission id' from the admission table rather than subject_id from the patients table during EDA. Choosing the former option allows us to draw relationships between a patient's stay and their death, rather than the patient's attributes measured over potentially a course of many visits and their death. Selecting the latter may obscure the results.\n",
    "## Features importance and frequency\n",
    "The following are the top 10 features with highest importance from MIMIC-III that affects Google's mortality prediction model:\n",
    "<ol>\n",
    "<li>Tidal Volume (set)</li>\n",
    "<li>Vti High</li>\n",
    "<li>Tidal Volume (Obser)</li>\n",
    "<li>Tidal Volume (observed)</li>\n",
    "<li>Temperature F</li>\n",
    "<li>calprevflg</li>\n",
    "<li>SpO2 Alarm [High]</li>\n",
    "<li>Temperature C (calc)</li>\n",
    "<li>Resp Rate (Spont)</li>\n",
    "<li>Tidal Volume (Set) (Yoon et al. supplementary information, 2023, p. 23)</li>\n",
    "</ol>\n",
    "\n",
    "The features found to have the greatest frequency in FIDDLE's preprocessed data, however, include:\n",
    "<ul>\n",
    "<li>heart rate</li>\n",
    "<li>respiratory rate</li>\n",
    "<li>temperature</li>\n",
    "<li>systolic\n",
    "blood pressure</li>\n",
    "<li>diastolic blood pressure</li>\n",
    "<li>peripheral oxygen\n",
    "saturation (Tang et al., 2020, p.25)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a090d48",
   "metadata": {},
   "source": [
    "## Table of Static Features in FIDDLE's experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918e9d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sqlalchemy engine to connect to database - ensure postgresql server is on\n",
    "sqluser = 'postgres'\n",
    "sqlpass = 'postgres'\n",
    "dbname = 'mimic'\n",
    "schema_name = 'mimiciii'\n",
    "host = 'localhost'\n",
    "port = 5432\n",
    "\n",
    "engine = db.create_engine(f\"postgresql+psycopg2://{sqluser}:{sqlpass}@{host}:{port}/{dbname}\")\n",
    "conn = engine.connect().execution_options(stream_results=True)\n",
    "\n",
    "# removed features names for privacy purposes\n",
    "query = f\"\"\"\n",
    "\n",
    "SELECT\n",
    "\n",
    "    -- Static features in FIDDLE's experiment. Remaining X features could not be located in MIMIC-III.\n",
    "    \n",
    "    [REMOVED FOR PRIVACY PURPOSES]\n",
    "\n",
    "FROM {schema_name}.patients patients\n",
    "\n",
    "LEFT JOIN {schema_name}.admissions adm\n",
    "ON patients.subject_id = adm.subject_id\n",
    "\n",
    "LEFT JOIN {schema_name}.icustays icu\n",
    "ON patients.subject_id = icu.subject_id\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "total_dfs = []\n",
    "\n",
    "# process query via chunking\n",
    "for chunk_dataframe in pd.read_sql(query, conn, chunksize=10000):\n",
    "    total_dfs.append(chunk_dataframe)\n",
    "\n",
    "# Concatenate all chunked dataframes then remove repeating icustays and itemid's\n",
    "df = pd.concat(total_dfs)\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985dfd32",
   "metadata": {},
   "source": [
    "# Split ICU Stays Based on Patients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c47e5a",
   "metadata": {},
   "source": [
    "The data splits are stratified by patients. The patient ID will be linked to the icu stay IDs. Based on which dataset the patient belongs, the icu stay ID will be grouped into the same one. Then outcomes of each adversity type will be categorised accordingly. Note that the mortality partition split has already been completed. Currently found issues cross-referencing IDs, so has not been implemented for the final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f8a6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "edited = False\n",
    "\n",
    "def count_raw(ls, element):\n",
    "    '''\n",
    "    Remove all instances of an element from an array.\n",
    "    '''\n",
    "    new_ls = [i for i in ls if i != element] \n",
    "    return new_ls\n",
    "\n",
    "# Only needs execution one time locally\n",
    "if not edited:\n",
    "    split_dir = '../databases/experiment_data/data_split'\n",
    "\n",
    "    # Define train, test, val for patient IDs\n",
    "    train_arr = []\n",
    "    test_arr = []\n",
    "    val_arr = []\n",
    "\n",
    "    train_patient = pd.read_csv(f'{split_dir}/train_listfile.csv')['stay']\n",
    "    for i in train_patient.index:\n",
    "\n",
    "        # Filter each row to only produce patient ID\n",
    "        row = train_patient.iloc[i]\n",
    "        train_arr.append(row[:row.index('_')])\n",
    "\n",
    "    test_patient = pd.read_csv(f'{split_dir}/test_listfile.csv')['stay']\n",
    "    for i in test_patient.index:\n",
    "\n",
    "        row = test_patient.iloc[i]\n",
    "        test_arr.append(row[:row.index('_')])\n",
    "\n",
    "    val_patient = pd.read_csv(f'{split_dir}/val_listfile.csv')['stay']\n",
    "    for i in val_patient.index:\n",
    "\n",
    "        row = val_patient.iloc[i]\n",
    "        val_arr.append(row[:row.index('_')])\n",
    "    \n",
    "    # Create a dictionary for patient ID:ICU ID\n",
    "    patient_to_icu = pd.read_csv(f'{split_dir}/all_stays.csv')\n",
    "    patient_to_icu = patient_to_icu[['SUBJECT_ID', 'ICUSTAY_ID']]    \n",
    "    \n",
    "    dict_p_icu = patient_to_icu.set_index('ICUSTAY_ID')['SUBJECT_ID'].to_dict()\n",
    "    \n",
    "    # Manually label each outcome for each adversity type\n",
    "    # ARF 4h\n",
    "    arf_4h_table = pd.read_csv(f'{split_dir}/ARF_4h.csv')\n",
    "    partition_data = []\n",
    "    icu_train = []\n",
    "    icu_val = []\n",
    "    icu_test = []\n",
    "    \n",
    "    unclassified_valid_id = []\n",
    "    invalid_id = []\n",
    "    # Assign partition label based on patient ID\n",
    "    for i in arf_4h_table.index:\n",
    "        try:\n",
    "            icu_id = arf_4h_table['ID'].iloc[i]\n",
    "            patient_id = str(dict_p_icu[icu_id])\n",
    "            \n",
    "        \n",
    "            if patient_id in train_arr:\n",
    "                partition_data.append('train')\n",
    "\n",
    "            elif patient_id in test_arr:\n",
    "                partition_data.append('test')\n",
    "\n",
    "            elif patient_id in val_arr:\n",
    "                partition_data.append('val')\n",
    "\n",
    "            # Patient ID is valid and not classified in train, test, or val\n",
    "            else:\n",
    "                unclassified_valid_id.append(patient_id)\n",
    "                \n",
    "                # To keep corresponding examples across files consistent\n",
    "                partition_data.append('X')\n",
    "        \n",
    "        # ICU ID in data files do not have a corresponding patient ID\n",
    "        except:\n",
    "            invalid_id.append(icu_id)\n",
    "            partition_data.append('X')\n",
    "            \n",
    "#     print(partition_data) \n",
    "        \n",
    "        \n",
    "# Read patient id and correspond it with icu id\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d0ac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total number of examples: {len(partition_data)}')\n",
    "print(f'Total number of classified examples: {len(count_raw(partition_data, \"X\"))}')\n",
    "print(f'Number valid ICU IDs in which their corresponding patient ID is not classified according to FIDDLEs source code files: {len(unclassified_valid_id)}')\n",
    "print(f'Number of invalid ICU IDs found in physionets dataset: {len(invalid_id)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a7a835",
   "metadata": {},
   "source": [
    "# Replication of FIDDLE's mortality experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4980004f",
   "metadata": {},
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12761462",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_directory = '../databases/experiment_data/population/mortality_48h.csv'\n",
    "directory_features = '../databases/experiment_data/features/mortality_48h'\n",
    "\n",
    "# Load independent variables\n",
    "s = sparse.load_npz(f'{directory_features}/s.npz').todense()\n",
    "X = sparse.load_npz(f'{directory_features}/X.npz').todense()\n",
    "\n",
    "# Load dependent variable - mortality outcome\n",
    "y = pd.read_csv(y_directory)['y_true']\n",
    "\n",
    "N,L,D = X.shape\n",
    "_,d = s.shape\n",
    "\n",
    "# Combine information to create full datasets - assuming order of y-labels matches order of independent features\n",
    "X_all = np.hstack([s, X.reshape((N,L*D))])\n",
    "y_all = y[:N]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_all = scaler.fit_transform(X_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f94cab8",
   "metadata": {},
   "source": [
    "## Combining Training and Validation Datasets for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed60acb8",
   "metadata": {},
   "source": [
    "FIDDLE's experiment combines the training and validation test sets for the logistic regression model on adversity outcomes (Page 7, Tang et al. 2021, Supplementary Information). A 5-fold cross validation method is used to evaluate the performance of the model with CV and a random search budget of 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbafa78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the 1) training + validation set, and 2) testing set separately.\n",
    "X_train_arr = []\n",
    "y_train_arr = []\n",
    " \n",
    "X_test_arr = []\n",
    "y_test_arr = []\n",
    "\n",
    "split_metadata = pd.read_csv(y_directory)['partition']\n",
    "\n",
    "for partition in range(len(split_metadata)):\n",
    "    \n",
    "    part = split_metadata[partition]\n",
    "    \n",
    "    # Classify cross-validation set\n",
    "    if part == 'train' or part == 'val':\n",
    "        \n",
    "        # Append corresponding example + outcome to training set\n",
    "        X_train_arr.append(X_all[partition])\n",
    "        y_train_arr.append(y_all[partition])\n",
    "        \n",
    "    # Classify testing set\n",
    "    elif part == 'test':\n",
    "        \n",
    "        # Append corresponding example + outcome to testing set\n",
    "        X_test_arr.append(X_all[partition])\n",
    "        y_test_arr.append(y_all[partition])\n",
    "        \n",
    "    else:\n",
    "        print('uh oh D:')\n",
    "\n",
    "X_train = np.array(X_train_arr)\n",
    "y_train = np.array(y_train_arr)\n",
    "\n",
    "X_test = np.array(X_test_arr)\n",
    "y_test = np.array(y_test_arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d44bc3",
   "metadata": {},
   "source": [
    "## Training LR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbba4f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Following specs were used to train:\n",
    "- mortality_model = LogisticRegression(solver='lbfgs', max_iter=10000)\n",
    "- macbook (16gb RAM, 2.3 GHz 8-Core Intel Core i9)\n",
    "- data split matches experiment\n",
    "\n",
    "\"\"\"\n",
    "cross_val = False\n",
    "\n",
    "if cross_val:\n",
    "\n",
    "    search_budget = 50\n",
    "    n_jobs = 50\n",
    "\n",
    "    mortality_model = RandomizedSearchCV(\n",
    "        LogisticRegression(solver='lbfgs'), \n",
    "        {'C': scipy.stats.reciprocal(1e-5, 1e5)},\n",
    "        n_iter=search_budget,\n",
    "        cv=StratifiedKFold(5),\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=n_jobs, \n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "elif not cross_val:\n",
    "    mortality_model = LogisticRegression(solver='lbfgs', max_iter=10000, C=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1af9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and store the model if file doesn't exist. Otherwise model reads from file.\n",
    "path_model = 'trained_models_2/mortality_48h.sav'\n",
    "\n",
    "if os.path.exists(path_model):\n",
    "    # Read pickle file\n",
    "    mortality_model = pickle.load(open(path_model, 'rb'))\n",
    "    \n",
    "else:\n",
    "    # Train model and store in file\n",
    "    mortality_model.fit(X_train, y_train)\n",
    "    pickle.dump(mortality_model, open(path_model, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99593b4",
   "metadata": {},
   "source": [
    "# Replication of FIDDLE's ARF 4h Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1292320e",
   "metadata": {},
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3ee247",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_directory = '../databases/experiment_data/population/ARF_4h.csv'\n",
    "directory_features = '../databases/experiment_data/features/ARF_4h'\n",
    "\n",
    "# Load independent variables\n",
    "s = sparse.load_npz(f'{directory_features}/s.npz').todense()\n",
    "X = sparse.load_npz(f'{directory_features}/X.npz').todense()\n",
    "\n",
    "# Load dependent variable\n",
    "y = pd.read_csv(y_directory)['ARF_LABEL']\n",
    "\n",
    "N,L,D = X.shape\n",
    "_,d = s.shape\n",
    "\n",
    "X_all = np.hstack([s, X.reshape((N,L*D))])\n",
    "y_all = y[:N]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_all = scaler.fit_transform(X_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f30bc8f",
   "metadata": {},
   "source": [
    "## Creating Training and Testing Datasets for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7e208a",
   "metadata": {},
   "source": [
    "Partitions for ARF and shock outcomes are unlabelled and were not published by FIDDLE. Random state 0 will be used to create datasets with a train:test ratio of 85:15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471a745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIND OUT MORE ABOUT PARTITIONS SINCE A COLUMN IS NOT GIVEN\n",
    "# Manually creating a training and testing split.\n",
    "\n",
    "X_train_arf4, X_test_arf4, y_train_arf4, y_test_arf4 = train_test_split(X_all, y_all, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b887e1fc",
   "metadata": {},
   "source": [
    "## Training LR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326faee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Following specs were used to train model:\n",
    "- same hyperparameters as FIDDLE except n_jobs = 7\n",
    "- macbook (16gb RAM, 2.3 GHz 8-Core Intel Core i9)\n",
    "- data split does not match experiment\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "cross_val = True\n",
    "\n",
    "if cross_val:\n",
    "\n",
    "    search_budget = 50\n",
    "    n_jobs = 50\n",
    "\n",
    "    arf_4h_model = RandomizedSearchCV(\n",
    "        LogisticRegression(solver='lbfgs', max_iter=100000), \n",
    "        {'C': scipy.stats.reciprocal(1e-5, 1e5)},\n",
    "        n_iter=search_budget,\n",
    "        cv=StratifiedKFold(5),\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=n_jobs,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "elif not cross_val:\n",
    "    arf_4h_model = LogisticRegression(solver='lbfgs', max_iter=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5836af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and store the model if file doesn't exist. Otherwise model reads from file.\n",
    "path_model = 'trained_models_2/arf_4h.sav'\n",
    "\n",
    "if os.path.exists(path_model):\n",
    "    # Read pickle file\n",
    "    arf_4h_model = pickle.load(open(path_model, 'rb'))\n",
    "    \n",
    "else:\n",
    "    # Train model and store in file\n",
    "    arf_4h_model.fit(X_train_arf4, y_train_arf4)\n",
    "    pickle.dump(arf_4h_model, open(path_model, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce161b22",
   "metadata": {},
   "source": [
    "# Replication of FIDDLE's ARF 12h Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4734316e",
   "metadata": {},
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36560514",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_directory = '../databases/experiment_data/population/ARF_12h.csv'\n",
    "directory_features = '../databases/experiment_data/features/ARF_12h'\n",
    "\n",
    "# Load independent variables\n",
    "s = sparse.load_npz(f'{directory_features}/s.npz').todense()\n",
    "X = sparse.load_npz(f'{directory_features}/X.npz').todense()\n",
    "\n",
    "# Load dependent variable\n",
    "y = pd.read_csv(y_directory)['ARF_LABEL']\n",
    "\n",
    "N,L,D = X.shape\n",
    "_,d = s.shape\n",
    "\n",
    "X_all = np.hstack([s, X.reshape((N,L*D))])\n",
    "y_all = y[:N]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_all = scaler.fit_transform(X_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6966b9",
   "metadata": {},
   "source": [
    "## Creating Training and Testing Datasets for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dab5021",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_arf12, X_test_arf12, y_train_arf12, y_test_arf12 = train_test_split(X_all, y_all, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45964ac",
   "metadata": {},
   "source": [
    "## Training LR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3660ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Following specs were used to train model:\n",
    "- same hyperparameters as FIDDLE except n_jobs = 3\n",
    "- desktop (32gb RAM, AMD Ryzen 3 3300X 4-Core Processor)\n",
    "- data split does not match experiment\n",
    "\"\"\"\n",
    "cross_val = False\n",
    "\n",
    "if cross_val:\n",
    "\n",
    "    search_budget = 50\n",
    "    n_jobs = 50\n",
    "\n",
    "    arf_12h_model = RandomizedSearchCV(\n",
    "        LogisticRegression(solver='lbfgs'), \n",
    "        {'C': scipy.stats.reciprocal(1e-5, 1e5)},\n",
    "        n_iter=search_budget,\n",
    "        cv=StratifiedKFold(5),\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=n_jobs, \n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "elif not cross_val:\n",
    "    arf_12h_model = LogisticRegression(solver='lbfgs', max_iter=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319e0ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and store the model if file doesn't exist. Otherwise model reads from file.\n",
    "path_model = 'trained_models_2/arf_12h.sav'\n",
    "\n",
    "if os.path.exists(path_model):\n",
    "    # Read pickle file\n",
    "    arf_12h_model = pickle.load(open(path_model, 'rb'))\n",
    "    \n",
    "else:\n",
    "    # Train model and store in file\n",
    "    arf_12h_model.fit(X_train_arf12, y_train_arf12)\n",
    "    pickle.dump(arf_12h_model, open(path_model, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258f0378",
   "metadata": {},
   "source": [
    "# Replication of FIDDLE's Shock 4h Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34791638",
   "metadata": {},
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c25b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_directory = '../databases/experiment_data/population/Shock_4h.csv'\n",
    "directory_features = '../databases/experiment_data/features/Shock_4h'\n",
    "\n",
    "# Load independent variables\n",
    "s = sparse.load_npz(f'{directory_features}/s.npz').todense()\n",
    "X = sparse.load_npz(f'{directory_features}/X.npz').todense()\n",
    "\n",
    "# Load dependent variable\n",
    "y = pd.read_csv(y_directory)['Shock_LABEL']\n",
    "\n",
    "N,L,D = X.shape\n",
    "_,d = s.shape\n",
    "\n",
    "X_all = np.hstack([s, X.reshape((N,L*D))])\n",
    "y_all = y[:N]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_all = scaler.fit_transform(X_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747abedb",
   "metadata": {},
   "source": [
    "## Creating Training and Testing Datasets for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3698c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_shock4, X_test_shock4, y_train_shock4, y_test_shock4 = train_test_split(X_all, y_all, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fe652c",
   "metadata": {},
   "source": [
    "## Training LR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98148ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Following specs were used to train model:\n",
    "- same hyperparameters as FIDDLE except n_jobs = 3\n",
    "- desktop (32gb RAM, AMD Ryzen 3 3300X 4-Corde Processor)\n",
    "- data split does not match experiment\n",
    "\"\"\"\n",
    "\n",
    "# Change to true if you have enough RAM to compute 250 fits\n",
    "cross_val = False\n",
    "\n",
    "if cross_val:\n",
    "\n",
    "    search_budget = 50\n",
    "    n_jobs = 50\n",
    "\n",
    "    shock_4h_model = RandomizedSearchCV(\n",
    "        LogisticRegression(solver='lbfgs'), \n",
    "        {'C': scipy.stats.reciprocal(1e-5, 1e5)},\n",
    "        n_iter=search_budget,\n",
    "        cv=StratifiedKFold(5),\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=n_jobs, \n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "elif not cross_val:\n",
    "    shock_4h_model = LogisticRegression(solver='lbfgs', max_iter=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b67fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and store the model if file doesn't exist. Otherwise model reads from file.\n",
    "path_model = 'trained_models_2/shock_4h.sav'\n",
    "\n",
    "if os.path.exists(path_model):\n",
    "    # Read pickle file\n",
    "    shock_4h_model = pickle.load(open(path_model, 'rb'))\n",
    "    \n",
    "else:\n",
    "    # Train model and store in file\n",
    "    shock_4h_model.fit(X_train_shock4, y_train_shock4)\n",
    "    pickle.dump(shock_4h_model, open(path_model, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4680d6aa",
   "metadata": {},
   "source": [
    "# Replication of FIDDLE's Shock 12h Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1292735e",
   "metadata": {},
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2da6752",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_directory = '../databases/experiment_data/population/Shock_12h.csv'\n",
    "directory_features = '../databases/experiment_data/features/Shock_12h'\n",
    "\n",
    "# Load independent variables\n",
    "s = sparse.load_npz(f'{directory_features}/s.npz').todense()\n",
    "X = sparse.load_npz(f'{directory_features}/X.npz').todense()\n",
    "\n",
    "# Load dependent variable\n",
    "y = pd.read_csv(y_directory)['Shock_LABEL']\n",
    "\n",
    "N,L,D = X.shape\n",
    "_,d = s.shape\n",
    "\n",
    "X_all = np.hstack([s, X.reshape((N,L*D))])\n",
    "y_all = y[:N]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_all = scaler.fit_transform(X_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f26761",
   "metadata": {},
   "source": [
    "## Creating Training and Testing Datasets for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4605c1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_shock12, X_test_shock12, y_train_shock12, y_test_shock12 = train_test_split(X_all, y_all, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97fd588",
   "metadata": {},
   "source": [
    "## Training LR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bf6b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Following specs were used to train model:\n",
    "- same hyperparameters as FIDDLE except n_jobs = 3\n",
    "- desktop (32gb RAM, AMD Ryzen 3 3300X 4-Corde Processor)\n",
    "- data split does not match experiment\n",
    "\"\"\"\n",
    "# Change to true if you have enough RAM to compute 250 fits\n",
    "cross_val = False\n",
    "\n",
    "if cross_val:\n",
    "\n",
    "    search_budget = 50\n",
    "    n_jobs = 50\n",
    "\n",
    "    shock_12h_model = RandomizedSearchCV(\n",
    "        LogisticRegression(solver='lbfgs'), \n",
    "        {'C': scipy.stats.reciprocal(1e-5, 1e5)},\n",
    "        n_iter=search_budget,\n",
    "        cv=StratifiedKFold(5),\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=n_jobs, \n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "elif not cross_val:\n",
    "    shock_12h_model = LogisticRegression(solver='lbfgs', max_iter=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f98cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and store the model if file doesn't exist. Otherwise model reads from file.\n",
    "path_model = 'trained_models_2/shock_12h.sav'\n",
    "\n",
    "if os.path.exists(path_model):\n",
    "    # Read pickle file\n",
    "    shock_12h_model = pickle.load(open(path_model, 'rb'))\n",
    "    \n",
    "else:\n",
    "    # Train model and store in file\n",
    "    shock_12h_model.fit(X_train_shock12, y_train_shock12)\n",
    "    pickle.dump(shock_12h_model, open(path_model, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b784c804",
   "metadata": {},
   "source": [
    "# Evaluating the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6605f26d",
   "metadata": {},
   "source": [
    "## Calculating AUROC and AUPR Scores\n",
    "Note that AUPRC has been calculated by directly calculating the area under the precision-recall curve using the trapezoidal rule instead of using the average_precision_score() method to increase accuracy of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbe4c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val = False\n",
    "\n",
    "if cross_val:\n",
    "    pass\n",
    "elif not cross_val:\n",
    "    # In-hospital mortality 48h outcome\n",
    "    prediction_test_scores_mortality = mortality_model.decision_function(X_test)\n",
    "    mortality_predict = mortality_model.predict(X_test)\n",
    "    \n",
    "    auroc_mortality = metrics.roc_auc_score(y_test, prediction_test_scores_mortality)\n",
    "    # Returns arrays containing precision, recall, thresholds. Then thresholds are removed, array positions are \n",
    "    # reversed. Area under that curve is calculated using trapezoidal rule.\n",
    "    aupr_mortality = metrics.auc(*metrics.precision_recall_curve(y_test, mortality_predict)[1::-1])\n",
    "\n",
    "    # ARF 4h\n",
    "    scores_arf_4h = arf_4h_model.decision_function(X_test_arf4)\n",
    "    arf_4h_predict = arf_4h_model.predict(X_test_arf4)\n",
    "\n",
    "    auroc_arf_4h = metrics.roc_auc_score(y_test_arf4, scores_arf_4h)\n",
    "    aupr_arf_4h = metrics.auc(*metrics.precision_recall_curve(y_test_arf4, arf_4h_predict)[1::-1])\n",
    "\n",
    "    # ARF 12h\n",
    "    scores_arf_12h = arf_12h_model.decision_function(X_test_arf12)\n",
    "    arf_12h_predict = arf_12h_model.predict(X_test_arf12)\n",
    "    \n",
    "    auroc_arf_12h = metrics.roc_auc_score(y_test_arf12, scores_arf_12h)\n",
    "    aupr_arf_12h = metrics.auc(*metrics.precision_recall_curve(y_test_arf12, arf_12h_predict)[1::-1])\n",
    "    \n",
    "    \n",
    "    # Shock 4h\n",
    "    scores_shock_4h = shock_4h_model.decision_function(X_test_shock4)\n",
    "    shock_4h_predict = shock_4h_model.predict(X_test_shock4)\n",
    "\n",
    "    auroc_shock_4h = metrics.roc_auc_score(y_test_shock4, scores_shock_4h)\n",
    "    aupr_shock_4h = metrics.auc(*metrics.precision_recall_curve(y_test_shock4, shock_4h_predict)[1::-1])\n",
    "\n",
    "    \n",
    "    # Shock 12h\n",
    "    scores_shock_12h = shock_12h_model.decision_function(X_test_shock12)\n",
    "    shock_12h_predict = shock_12h_model.predict(X_test_shock12)\n",
    "\n",
    "    auroc_shock_12h = metrics.roc_auc_score(y_test_shock12, scores_shock_12h)\n",
    "    aupr_shock_12h = metrics.auc(*metrics.precision_recall_curve(y_test_shock12, shock_12h_predict)[1::-1])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02abd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[0.856,0.444,0.817,0.657,0.757,0.291,0.825,0.548,0.792,0.274],\n",
    "        [\n",
    "            auroc_mortality,aupr_mortality,\n",
    "            auroc_arf_4h,aupr_arf_4h,\n",
    "            auroc_arf_12h,aupr_arf_12h,\n",
    "            auroc_shock_4h,aupr_shock_4h,\n",
    "            auroc_shock_12h,aupr_shock_12h\n",
    "        ], \n",
    "        [0,0,0,0,0,0,0,0,0,0]\n",
    "       ]\n",
    "\n",
    "header = pd.MultiIndex.from_product([['In-hospital mortality 48h',\n",
    "                                      'Acute Respiratory Failure 4h', \n",
    "                                      'Acute Respiratory Failure 12h',\n",
    "                                      'Shock 4h',\n",
    "                                      'Shock 12h'],\n",
    "                                     ['AUROC', 'AUPR']],\n",
    "                                    names=['Adversity Outcome','Metric'])\n",
    "metrics_table = pd.DataFrame(data, \n",
    "                  index=['Original','Replicated','Replicated Synthetic'], \n",
    "                  columns=header)\n",
    "metrics_table = metrics_table.round(3)\n",
    "display(metrics_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab672d5",
   "metadata": {},
   "source": [
    "## Hyperparameters used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1720808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display hyperparameters used for each experiment\n",
    "\n",
    "mortality_C = mortality_model.get_params()['C'] # Randomised Search CV was not used\n",
    "arf_4h_C = arf_4h_model.best_params_['C']\n",
    "arf_12h_C = arf_12h_model.best_params_['C']\n",
    "shock_4h_C = shock_4h_model.best_params_['C']\n",
    "shock_12h_C = shock_12h_model.best_params_['C']\n",
    "\n",
    "hyperparameters = [\"Inverse of Regularisation Strength ('C')\"]\n",
    "\n",
    "hyper_table = pd.DataFrame(\n",
    "    {\n",
    "        'In-hospital mortality 48h': [mortality_C],\n",
    "        'Acute Respiratory Failure 4h': [arf_4h_C],\n",
    "        'Acute Respiratory Failure 12h': [arf_12h_C],\n",
    "        'Shock 4h': [shock_4h_C],\n",
    "        'Shock 12h': [shock_12h_C]\n",
    "    },\n",
    "    index = hyperparameters\n",
    "\n",
    ")\n",
    "\n",
    "display(hyper_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b36f021",
   "metadata": {},
   "source": [
    "## Confusion Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ba9b43",
   "metadata": {},
   "source": [
    "Definition of labels:\n",
    "<ul>\n",
    "<li>0 indicates that the patient does not experience the adverse outcome after t=T hours of being admitted into ICU</li>\n",
    "<li>1 indicates that the patient does experience the adverse outcome after t=T hours of being admitted into ICU.</li>\n",
    "</ul>\n",
    "General trends:\n",
    "<ul>\n",
    "    <li> There seems to be a high proportion of False Negative results (bottom-left)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aa3a60",
   "metadata": {},
   "source": [
    "### In-hospital mortality 48h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb20738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/mlearning-ai/heatmap-for-correlation-matrix-confusion-matrix-extra-tips-on-machine-learning-b0377cee31c2\n",
    "\n",
    "sns.set(font_scale=1.4)\n",
    "conf_mtrx = metrics.confusion_matrix(y_test, mortality_predict)\n",
    "test_counts = [\"{0:0.0f}\".format(value) for value in conf_mtrx.flatten()]\n",
    "test_percentage = [\"{0:.2%}\".format(value) for value in conf_mtrx .flatten()/np.sum(conf_mtrx)]\n",
    "test_labels = [f\"{v2}\\n{v3}\" for v2, v3 in zip(test_counts,test_percentage)]\n",
    "test_labels = np.asarray(test_labels).reshape(2,2)\n",
    "\n",
    "plt.figure(figsize = (12,5))\n",
    "display_conf_mtrx = sns.heatmap(conf_mtrx, annot=test_labels, fmt='', cmap='Blues')\n",
    "display_conf_mtrx.set_xlabel('Predicted Label', fontsize=25)\n",
    "display_conf_mtrx.set_ylabel('Actual Label', fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af168e2",
   "metadata": {},
   "source": [
    "### Acute Respiratory Failure 4h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5695a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.4)\n",
    "conf_mtrx = metrics.confusion_matrix(y_test_arf4, arf_4h_predict)\n",
    "test_counts = [\"{0:0.0f}\".format(value) for value in conf_mtrx.flatten()]\n",
    "test_percentage = [\"{0:.2%}\".format(value) for value in conf_mtrx .flatten()/np.sum(conf_mtrx)]\n",
    "test_labels = [f\"{v2}\\n{v3}\" for v2, v3 in zip(test_counts,test_percentage)]\n",
    "test_labels = np.asarray(test_labels).reshape(2,2)\n",
    "\n",
    "plt.figure(figsize = (12,5))\n",
    "display_conf_mtrx = sns.heatmap(conf_mtrx, annot=test_labels, fmt='', cmap='Blues')\n",
    "display_conf_mtrx.set_xlabel('Predicted Label', fontsize=25)\n",
    "display_conf_mtrx.set_ylabel('Actual Label', fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0585aa7b",
   "metadata": {},
   "source": [
    "### Acute Respiratory Failure 12h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04e60cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.4)\n",
    "conf_mtrx = metrics.confusion_matrix(y_test_arf12, arf_12h_predict)\n",
    "test_counts = [\"{0:0.0f}\".format(value) for value in conf_mtrx.flatten()]\n",
    "test_percentage = [\"{0:.2%}\".format(value) for value in conf_mtrx .flatten()/np.sum(conf_mtrx)]\n",
    "test_labels = [f\"{v2}\\n{v3}\" for v2, v3 in zip(test_counts,test_percentage)]\n",
    "test_labels = np.asarray(test_labels).reshape(2,2)\n",
    "\n",
    "plt.figure(figsize = (12,5))\n",
    "display_conf_mtrx = sns.heatmap(conf_mtrx, annot=test_labels, fmt='', cmap='Blues')\n",
    "display_conf_mtrx.set_xlabel('Predicted Label', fontsize=25)\n",
    "display_conf_mtrx.set_ylabel('Actual Label', fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590cad86",
   "metadata": {},
   "source": [
    "### Shock 4h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1b9d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.4)\n",
    "conf_mtrx = metrics.confusion_matrix(y_test_shock4, shock_4h_predict)\n",
    "test_counts = [\"{0:0.0f}\".format(value) for value in conf_mtrx.flatten()]\n",
    "test_percentage = [\"{0:.2%}\".format(value) for value in conf_mtrx .flatten()/np.sum(conf_mtrx)]\n",
    "test_labels = [f\"{v2}\\n{v3}\" for v2, v3 in zip(test_counts,test_percentage)]\n",
    "test_labels = np.asarray(test_labels).reshape(2,2)\n",
    "\n",
    "plt.figure(figsize = (12,5))\n",
    "display_conf_mtrx = sns.heatmap(conf_mtrx, annot=test_labels, fmt='', cmap='Blues')\n",
    "display_conf_mtrx.set_xlabel('Predicted Label', fontsize=25)\n",
    "display_conf_mtrx.set_ylabel('Actual Label', fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b059b1e",
   "metadata": {},
   "source": [
    "### Shock 12h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4853cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.4)\n",
    "conf_mtrx = metrics.confusion_matrix(y_test_shock12, shock_12h_predict)\n",
    "test_counts = [\"{0:0.0f}\".format(value) for value in conf_mtrx.flatten()]\n",
    "test_percentage = [\"{0:.2%}\".format(value) for value in conf_mtrx .flatten()/np.sum(conf_mtrx)]\n",
    "test_labels = [f\"{v2}\\n{v3}\" for v2, v3 in zip(test_counts,test_percentage)]\n",
    "test_labels = np.asarray(test_labels).reshape(2,2)\n",
    "\n",
    "plt.figure(figsize = (12,5))\n",
    "display_conf_mtrx = sns.heatmap(conf_mtrx, annot=test_labels, fmt='', cmap='Blues')\n",
    "display_conf_mtrx.set_xlabel('Predicted Label', fontsize=25)\n",
    "display_conf_mtrx.set_ylabel('Actual Label', fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034ebd2b",
   "metadata": {},
   "source": [
    "## ROC Curves and PR Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb720009",
   "metadata": {},
   "source": [
    "Each PR Curve has a different baseline, while ROC curves can be compared to the same naive classifer metric. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dd8370",
   "metadata": {},
   "source": [
    "### In-hospital Mortality 48h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682d37d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of predict_proba method is [% of 0 outcome, % of 1 outcome]\n",
    "prediction_prob_mortality48h = mortality_model.predict_proba(X_test)\n",
    "\n",
    "# [:, 1] selects all rows, then selects column with index 1. Purpose is to get probabilities of all positive outcomes.\n",
    "fpr_mortality48h, tpr_mortality48h, thresh_mortality48h = metrics.roc_curve(y_test, prediction_prob_mortality48h[:,1], pos_label=1)\n",
    "\n",
    "mortality_precision, mortality_recall, _ = metrics.precision_recall_curve(y_test, prediction_prob_mortality48h[:,1])\n",
    "\n",
    "# true positive rate = false positive rate\n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "x_mortality48h, y_mortality48h, _ = metrics.roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae34b4e",
   "metadata": {},
   "source": [
    "### ARF 4h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4218c210",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_prob_arf4h = arf_4h_model.predict_proba(X_test_arf4)\n",
    "\n",
    "# ROC\n",
    "fpr_arf4h, tpr_arf4h, thresh_arf4h = metrics.roc_curve(y_test_arf4, prediction_prob_arf4h[:,1], pos_label=1)\n",
    "\n",
    "# PR\n",
    "arf4h_precision, arf4h_recall, _ = metrics.precision_recall_curve(y_test_arf4, prediction_prob_arf4h[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1643b67",
   "metadata": {},
   "source": [
    "### ARF 12h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa477d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_prob_arf12h = arf_12h_model.predict_proba(X_test_arf12)\n",
    "\n",
    "# ROC\n",
    "fpr_arf12h, tpr_arf12h, thresh_arf12h = metrics.roc_curve(y_test_arf12, prediction_prob_arf12h[:,1], pos_label=1)\n",
    "\n",
    "# PR\n",
    "arf12h_precision, arf12h_recall, _ = metrics.precision_recall_curve(y_test_arf12, prediction_prob_arf12h[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3093e387",
   "metadata": {},
   "source": [
    "### Shock 4h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c060f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_prob_shock4h = shock_4h_model.predict_proba(X_test_shock4)\n",
    "\n",
    "# ROC\n",
    "fpr_shock4h, tpr_shock4h, thresh_shock4h = metrics.roc_curve(y_test_shock4, prediction_prob_shock4h[:,1], pos_label=1)\n",
    "\n",
    "# PR\n",
    "shock4h_precision, shock4h_recall, _ = metrics.precision_recall_curve(y_test_shock4, prediction_prob_shock4h[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c1883e",
   "metadata": {},
   "source": [
    "### Shock 12h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d3841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_prob_shock12h = shock_12h_model.predict_proba(X_test_shock12)\n",
    "\n",
    "# ROC\n",
    "fpr_shock12h, tpr_shock12h, thresh_shock12h = metrics.roc_curve(y_test_shock12, prediction_prob_shock12h[:,1], pos_label=1)\n",
    "\n",
    "# PR\n",
    "shock12h_precision, shock12h_recall, _ = metrics.precision_recall_curve(y_test_shock12, prediction_prob_shock12h[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3876b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot roc curves\n",
    "plt.plot(fpr_mortality48h, tpr_mortality48h, linestyle='--', color='red', label=\"Mortality 48h\")\n",
    "plt.plot(fpr_arf4h, tpr_arf4h, linestyle='--',color='orange', label='ARF 4h')\n",
    "plt.plot(fpr_arf12h, tpr_arf12h, linestyle='--',color='yellow', label='ARF 12h')\n",
    "plt.plot(fpr_shock4h, tpr_shock4h, linestyle='--',color='green', label='Shock 4h')\n",
    "plt.plot(fpr_shock12h, tpr_shock12h, linestyle='--',color='blue', label='Shock 12h')\n",
    "\n",
    "plt.plot(x_mortality48h, y_mortality48h, linestyle='--', color='purple')\n",
    "\n",
    "# title and labels\n",
    "plt.title('ROC Curves for FIDDLE Experiments')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac1fc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PR Curves\n",
    "\n",
    "# In-hospital mortality 48h\n",
    "# Calculate the baseline by assuming all outcomes are predicted positive\n",
    "baseline_mortality = len(y_test[y_test==1]) / len(y_test)\n",
    "plt.plot([0, 1], [baseline_mortality, baseline_mortality], linestyle='--', label='Baseline')\n",
    "plt.plot(mortality_recall, mortality_precision, linestyle='--', label='Mortality 48h')\n",
    "\n",
    "# Title and labels\n",
    "plt.title('Precision-Recall Curve for In-Hospital Mortality 48h')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3587689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_arf4h = len(y_test_arf4[y_test_arf4==1]) / len(y_test_arf4)\n",
    "\n",
    "# ARF 4h\n",
    "plt.plot([0, 1], [baseline_arf4h, baseline_arf4h], linestyle='--', label='Baseline')\n",
    "plt.plot(arf4h_recall, arf4h_precision, linestyle='--', label='ARF 4h')\n",
    "\n",
    "# Title and labels\n",
    "plt.title('Precision-Recall Curve for ARF 4h')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79073ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_arf12h = len(y_test_arf12[y_test_arf12==1]) / len(y_test_arf12)\n",
    "\n",
    "# ARF 12h\n",
    "plt.plot([0, 1], [baseline_arf12h, baseline_arf12h], linestyle='--', label='Baseline')\n",
    "plt.plot(arf12h_recall, arf12h_precision, linestyle='--', label='ARF 12h')\n",
    "\n",
    "# Title and labels\n",
    "plt.title('Precision-Recall Curve for ARF 12h')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63ec733",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_shock4h = len(y_test_shock4[y_test_shock4==1]) / len(y_test_shock4)\n",
    "\n",
    "# Shock 4h\n",
    "plt.plot([0, 1], [baseline_shock4h, baseline_shock4h], linestyle='--', label='Baseline')\n",
    "plt.plot(shock4h_recall, shock4h_precision, linestyle='--', label='Shock 4h')\n",
    "\n",
    "# Title and labels\n",
    "plt.title('Precision-Recall Curve for Shock 4h')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a40f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_shock12h = len(y_test_shock12[y_test_shock12==1]) / len(y_test_shock12)\n",
    "\n",
    "# Shock 12h\n",
    "plt.plot([0, 1], [baseline_shock12h, baseline_shock12h], linestyle='--', label='Baseline')\n",
    "plt.plot(shock12h_recall, shock12h_precision, linestyle='--', label='Shock 12h')\n",
    "\n",
    "# Title and labels\n",
    "plt.title('Precision-Recall Curve for Shock 12h')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
